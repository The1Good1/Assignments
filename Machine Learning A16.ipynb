{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc42bbd",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. In a linear equation, what is the difference between a dependent variable and an independent variable?\n",
    "\n",
    "2. What is the concept of simple linear regression? Give a specific example.\n",
    "\n",
    "3. In a linear regression, define the slope.\n",
    "\n",
    "4. Determine the graph&#39;s slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2).\n",
    "\n",
    "5. In linear regression, what are the conditions for a positive slope?\n",
    "\n",
    "6. In linear regression, what are the conditions for a negative slope?\n",
    "\n",
    "7. What is multiple linear regression and how does it work?\n",
    "\n",
    "8. In multiple linear regression, define the number of squares due to error.\n",
    "\n",
    "9. In multiple linear regression, define the number of squares due to regression.\n",
    "\n",
    "10. In a regression equation, what is multicollinearity?\n",
    "\n",
    "11. What is heteroskedasticity, and what does it mean?\n",
    "\n",
    "12. Describe the concept of ridge regression.\n",
    "\n",
    "13. Describe the concept of lasso regression.\n",
    "\n",
    "14. What is polynomial regression and how does it work?\n",
    "\n",
    "15. Describe the basis function.\n",
    "\n",
    "16. Describe how logistic regression works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd9366",
   "metadata": {},
   "source": [
    "# Ans 1\n",
    "\n",
    "In a linear equation, the dependent variable is the variable that is being predicted or explained by the independent variable. The dependent variable is the output or outcome of the equation, while the independent variable is the input or predictor variable that is used to explain or predict the value of the dependent variable.\n",
    "\n",
    "# Ans 2\n",
    "\n",
    "Simple linear regression is a statistical technique used to model the relationship between two variables by fitting a linear equation to the observed data. It assumes a linear relationship between the independent variable (X) and the dependent variable (Y). For example, suppose we want to study the relationship between the number of hours studied (X) and the exam score (Y). We collect data on several students, recording the number of hours they studied and their corresponding exam scores. By performing simple linear regression, we can estimate the equation of the line that best fits the data and use it to predict the exam score based on the number of hours studied.\n",
    "\n",
    "# Ans 3\n",
    "\n",
    "In linear regression, the slope represents the change in the dependent variable (Y) for a unit change in the independent variable (X). It indicates the steepness or direction of the linear relationship between the variables. The slope is denoted by the coefficient β₁ in the linear regression equation Y = β₀ + β₁X.\n",
    "\n",
    "# Ans 4\n",
    "\n",
    "To determine the slope of the line passing through the points (3, 2) and (2, 2), we can use the slope formula:\n",
    "\n",
    "slope = (Y₂ - Y₁) / (X₂ - X₁)\n",
    "= (2 - 2) / (2 - 3)\n",
    "= 0 / -1\n",
    "= 0\n",
    "\n",
    "Therefore, the slope of the line is 0.\n",
    "\n",
    "# Ans 5\n",
    "\n",
    "The conditions for a positive slope in linear regression are that as the independent variable (X) increases, the dependent variable (Y) also increases. This indicates a positive linear relationship between the variables.\n",
    "\n",
    "# Ans 6\n",
    "\n",
    "Multiple linear regression is an extension of simple linear regression that involves multiple independent variables to predict the dependent variable. It models the relationship between the dependent variable and two or more independent variables by fitting a linear equation to the observed data. The equation takes the form Y = β₀ + β₁X₁ + β₂X₂ + ... + βₚXₚ, where Y is the dependent variable, X₁, X₂, ..., Xₚ are the independent variables, and β₀, β₁, β₂, ..., βₚ are the coefficients.\n",
    "\n",
    "# Ans 7\n",
    "\n",
    "In multiple linear regression, the sum of squares due to error (SSE) represents the variability or dispersion of the observed data points around the regression line. It measures the discrepancy between the actual values and the predicted values by the regression model.\n",
    "\n",
    "# Ans 8\n",
    "\n",
    "In multiple linear regression, the sum of squares due to regression (SSR) represents the variability or dispersion of the predicted values around the overall mean of the dependent variable. It measures the amount of variability in the dependent variable that is explained by the independent variables in the regression model.\n",
    "\n",
    "# Ans 9\n",
    "\n",
    "In a regression equation, multicollinearity refers to a situation where two or more independent variables are highly correlated with each other. It can cause issues in the regression analysis, such as unstable or unreliable estimates of the regression coefficients. Multicollinearity makes it difficult to determine the unique contribution of each independent variable to the dependent variable.\n",
    "\n",
    "# Ans 10\n",
    "\n",
    "Heteroskedasticity refers to a situation in regression analysis where the variability of the errors or residuals is not constant across different levels of the independent variable(s). It violates the assumption of homoscedasticity, which assumes that the variance of the errors is constant. Heteroskedasticity can affect the accuracy and reliability of the regression model's estimates and statistical tests.\n",
    "\n",
    "# Ans 11\n",
    "\n",
    "Ridge regression is a regularization technique used in linear regression to handle multicollinearity and reduce the impact of irrelevant or highly correlated independent variables. It adds a penalty term to the ordinary least squares objective function, which shrinks the regression coefficients towards zero. Ridge regression can help prevent overfitting and improve the stability of the regression model.\n",
    "\n",
    "# Ans 12\n",
    "\n",
    "Lasso regression, also known as Least Absolute Shrinkage and Selection Operator, is another regularization technique used in linear regression. Similar to ridge regression, it adds a penalty term to the objective function. However, lasso regression uses the L1 norm penalty, which encourages sparsity in the regression coefficients. It tends to set some coefficients exactly to zero, effectively performing feature selection and producing a more interpretable model.\n",
    "\n",
    "# Ans 13\n",
    "\n",
    "Polynomial regression is a form of regression analysis where the relationship between the independent variable(s) and the dependent variable is modeled as an nth-degree polynomial. It allows for capturing nonlinear relationships between the variables by including polynomial terms in the regression equation. For example, a second-degree polynomial regression equation would have terms like X² and X³ in addition to the linear term X.\n",
    "\n",
    "# Ans 14\n",
    "\n",
    "In polynomial regression, the basis functions are the polynomial terms used to model the relationship between the independent variable(s) and the dependent variable. These basis functions are created by taking powers and combinations of the independent variable(s) up to a certain degree. The basis functions form the basis for fitting the polynomial regression model to the data.\n",
    "\n",
    "# Ans 15\n",
    "\n",
    "Logistic regression is a statistical model used to predict binary outcomes or probabilities. It is commonly used for classification problems where the dependent variable is categorical. Instead of fitting a straight line, logistic regression models the relationship between the independent variables and the log-odds of the dependent variable using the logistic function (sigmoid function). It estimates the probabilities of the different classes based on the values of the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69039106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
